<!doctype html>
<meta charset="utf-8">
<script src="template.js"></script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['\\(','\\)']]}
});
</script>

<script type="text/front-matter">
  title: "Investigating the Similarities Between Satire and Misleading News Headlines"
  description: "An investigation on the similarities between satire and reliable news headlines, and how they can help determine the strategies used in other forms of misleading or fake news."
  authors:
  - Violet Burbank
  affiliations:
  - Computer Science and Mathematics, Harvey Mudd College
</script>

<dt-article>
<h1>Investigating the Similarities Between Satire and Misleading News Headlines</h1>
<h2>An investigation on the similarities between satire and reliable news headlines, and how they can help determine the strategies used in other forms of misleading or fake news.</h2>
<dt-byline></dt-byline>
    <hr>
<p><strong>TL;DR</strong> Using the Fake News Corpus dataset, I created a logistic regression model to differentiate between reliable and satire news headlines. This model demonstrated that conspiracy and clickbait headlines tend to be more similar to satire than reliable headlines.</p>
    <hr>
<p>While humans are fairly adept at recognizing sarcasm from seriousness, the prevalence of fake news and outlandish headlines have been making it much harder to determine what is real in the media. In this article we will attempt to create a model to differentiate between real and satire news headline text. We can also apply this model to various other types of news to investigate whether the text and writing is more similar to that of reliable or satire news. This article will explore conspiracy, clickbait and fake news. All of these types of news attempt to pass themselves off as reliable news in order to either gain more traffic on their sites or possibly further a political agenda. While the goal is for the headlines to be interpretted a real, the contents tend to be more outlandish and sensational, which is more simialr to satire. By comparing the contents of each type to the reliable and satire news, we can find out whether the headliens are crafted realistically enough to pass as reliable news, or if the content itself will give it away as not being real.</p>
<section>   
<h2>Obtaining and Cleaning the Data</h2>
<p>I decided to use the open source dataset Fake News Corpus <dt-fn>github repo available <a href = "https://github.com/several27/FakeNewsCorpus">here</a> </dt-fn> to provide the satire and credible news headlines. The dataset itself consists of over 6 million articles<dt-fn>To be more precise, there are 8,247,542 articles represented</dt-fn> classified<dt-fn>The original source used <a href = "https://github.com/several27/FakeNewsCorpus">http://www.opensources.co/</a> to classify each domain, but this site has since closed down.</dt-fn> into different types such as credible, satire, fake news, and so on. It is important to note that the data is classified into each type based solely off the domain of the article rather than the content article itself. In order to make this data easier to work with, I cleaned the raw  csv to eliminate unnecessary columns, non-ascii characters, and rows with types that did not fall into the categories outlined by the original corpus. </p>
<p>To get a better idea of where our news is coming from, let's explore the domains under the credible and the satire types. In the original dataset, the domain names were expressed as the news site they were scraped from, and thus included url extensions. To standardize the domain names, I eliminated punctuation and stop words<dt-fn>The complete list of stopwords used: ["com", "www", "org", "co", "uk", "aus", "domain", "columns", "rows", "au", "af", "ca", "go", "de", "in", "nz", "m", "net"]</dt-fn>. After doing this, we can better visualize the domains classified as reliable news and satire news and their relative frequencies<dt-fn>The distribution of these sites is very skewed, with the most common sites appearing exponentially more often than the others. Note the scale of the plots, as well as the difference in size between the reliable and the satire news. There are roughly 1,920,139 reliable news and 146,080 satire articles represented.</dt-fn>.</p>
<feature>
    <img src="images/credible_news_domains.png"
     alt = "A bar chart demonstrating the frequencies of credible news domains in our dataset"
     align = "center"
     width="500"
     height="375"
     title = "Reliable news domains in the Fake News Corpus dataset"
     hspace = "10">
<img src="images/satire_news_domains.png"
     alt = "A bar chart demonstrating the frequencies of satire news domains in our dataset"
     align = "center"
     width="500"
     height="375"
     title = "Satire news domains in the Fake News Corpus dataset"
      hspace = "10">
<p><figcaption>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fig. 1 Bar plots demonstrating the domains of the satire news (right) and reliable news (left).</figcaption></p>
</feature>
</section>  

    <section>
<p>Most of these sources should be recognizable, and all have a significant web presence. We can see that the reliable news sites have a variety of specialties, from financial news to sports news to current events. Note that in the original dataset news classified as political or biased are in their own categories, meaning that all of the domains represented are more or less non partisan, and are not trying to serve a certain agenda. This will help us to create a model that will not be skewed towards certain political beliefs or persuasive techniques. The satire news domains are all strictly satire news, and could be on a variety of topics. We definitely have a lot of political headlines present, and most are not trying to promote an idealogy as much as poke fun. Now that we have a better idea of what data we are working with, we can begin training a model.</p>
<h2>Creating and Adjusting a Model</h2>
<p>So, let's create a classifier to determine whether an article is reliable or satirical. I used the SciKitLearn Count Vectorizer<dt-fn>documentation found <a href = "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">here</a></dt-fn> to create a bag of words model for our data. I also split the data into test and training sets stratified by type. By doing this, we retain the proportions of satire and reliable news represented in the test and training datasets. This will prevent us from having a training dataset entirely compromised of one type of news, skewing the model. Finally, I constructed a logistic regression model<dt-fn>built with SciKit Learn, documentation found <a href = "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html">here</a></dt-fn> To visualize the accuracy of the model I created a confusion matrix<dt-fn>further information and documentation found <a href = "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html">here</a></dt-fn> to demonstrate what each observation in the test set is being classified as.</p>
<feature>
    <img src="images/cm_total.png"
 alt = "A confusion matrix demonstrating the accuracy of the model in classifying articles. Total accuracy is roughly .96"
 align = "center"
 width="750"
 height="550"
 title = "Confusion matrix of running logistic regression on the entire dataset."
 hspace = "50">
<p><figcaption>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fig. 2 Confusion matrix of the entire dataset demonstrating high accuracy</figcaption></p>
</feature>
<p>This figure shows us how our model is performing in classifying reliable news and satire news. Looking at this, we see a fairly high accuracy rate. while this is promising, looking a bit closer we see that the satire data has a very high false negative rate. Roughly 60% of our satire data is being misclassified. This is becuase the satire data is being clobbered by the real news data as there is significantly more reliable news data than satire. In fact, if we were to classify all headlines as credible news, we would see an accuracy of .95! This is not quite what we wanted, since we are trying to classify articles based off of their headline text content rather than pure probability. So, in order to better understand the problem let's examine a Receiver Operating Characteristic Curve (ROC Curve). The ROC Curve will show us the performance of this logistic regression model as our discrimination threshold is varied. It will compare the true positive rate with the false positive rate<dt-fn>More information and documentation found <a href = "https://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics">here</a></dt-fn>. Note that a model with perfect accuracy will have the area under the curve be exactly one.</p>
<feature>
    <img src="images/roc_total.png"
 alt = "A ROC Curve demonstrating the low true positive rate. The total area under the curve is .93."
 align = "center"
 width="500"
 height="350"
 title = "ROC curve demonstrating the low true positive rate implicit in our data"
 hspace="150">
    <p><figcaption>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fig.3 ROC curve demonstrating the low true positive rate implicit in our data.</figcaption></p>
</feature>
<p>The area under the ROC curve is very large, indicating our model is very accurate. However, as we noticed this is because we tend to have a lot of false negatives classifying satire news as real news. If we were to actually implement this in order to discern real and satire news articles this would be problematic, so lets try and shift along the ROC curve to an area with lower false negative rates. We are trying to make a model that can discern between reliable and satire news based off of how they are written rather the actual frequencies of reliable versus satire news. Even though there are many more reliable news headlines both in this dataset and the real world, we want to ensure that we are solely classifying based off of the text content of the title rather than these outside factors. This will create a model that will be more effective at classifying both satire and reliable news in general, rather than when we have significantly more real news than satire. We will need to sacrifice some accuracy and true positive rates to change this. So, I attemped to create a new reliable news dataset using a stratified sample from our total data by domain<dt-fn>This processing will essentially be lowering the number of values in our dataset, n, and thus will increase estimation error and generalization error. While it is not ideal to be raising error, we do want to lower our approximation error created by simply assuming a lot of the satire articles are actually reliable.</dt-fn>. I sampled the data to have equal amounts of real and satire news. Then we can create a new logistic regression model that wil hopefully be more effective at classifying satire news headlines. We get a confusion matrix as such: </p>
<feature>
    <img 
  src="images/cm_strat.png"
 title = "Confusion matrix"
 alt = "A confusion matrix demonstrating the accuracy of the model in classifying articles. Total accuracy is roughly .85"
 align = "center"
 width="500"
 height="500"
 hspace="150">
<p><figcaption>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fig.4 Confusion matrix for a smaller real news population.</figcaption></p>
</feature>


<p>While this model is significantly less accurate than the one above, we do see a better false negative rate. More than 80% of our satire articles are being classified correctly. However, we do see a larger false positive rate, with roughly 15% of reliable news headlines being classified as satire news. This is acceptable, as we do see the majority of both reliable and satire news being classified correctly, which was not the case in our previous model with all of the data. </p>
<p>    
Now, we will use this model on some of the other types and see which ones get classified as satire versus real news. I decided to focus on conspiracy news, fake news, and clickbait news as these types tend to have the most outlandish headlines that attempt to pass as credible news yet in reality are not. I would like to see whether these different types of news are classified as being more similar to satire news headlines or credible news headlines by seeing how the headlines from my dataset get classified.</p>
        </section>
    
<section>
<h2>Trying the Model on Conspiracy, Fake, and Clickbait News</h2>
<p>Our dataset has about 905,981 conspiracy articles, 928,083 fake news articles and 292,201 clickbait articles represented. After cleaning them and vectorizing them in the same way as the satire and reliable news, we can run them through the classified constructed above to see what label the data will get assigned. By seeing which classification they tend to be assigned, we can determine whether each type of misleading news is has headline style more similar to reliable or satire news.</p>
    <feature>
    <img 
  src="images/rel_sat_class.png"
 title = "Classifications of Misleading News Types into Reliable and Satire News"
 align = "center"
 width="800"
 height="550"
 hspace="150">
    </feature>

<p>As we can see, every classification of headline is predicted to be satire news more often than reliable news. While conspiracy news and clickbait news have a much higher rate of classification as satire news, fake news is more even. This is likely because the conspiracy and clickbait headlines are much more outlandish in their content, unlike the real news which reports on more than just sensationalist stories, but focusses on even mundane news. Fake news is often aimed to be more simliar to real news, as the entire point is usually to convince readers that the false information being communicated is true.</p>
    
    
</section>
<section>  
    <h2>Conclusion and Further Development</h2>
    <p>Overall, from this analysis we can say with some degree of certainty that conspiracy, fake, and clickbait news headlines tend to be more similar to satire news. While I cannot single out exactly what traits are most similar (eg word choice, punctiation...) we can see that the they are more similar to satire rather than reliable news. In a further examination on this topic I would like to look further into ways to tune the initial classifier to be more accurate, since it has a fairly high error rate. The results could be due to variability, or some other hidden factors I have not considered. I would also like to analyze different domains to see if some tend to have different styles that lend themselve more to satire or reliable.</p>
</section>
</dt-article>
<dt-appendix>
</dt-appendix>

<script type="text/bibliography">
  @article{gregor2015draw,
    title={DRAW: A recurrent neural network for image generation},
    author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
    journal={arXivreprint arXiv:1502.04623},
    year={2015},
    url={https://arxiv.org/pdf/1502.04623.pdf}
  }
</script>
